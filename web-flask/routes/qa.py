
"""
æ™ºèƒ½é—®ç­”è·¯ç”±
åŸºäºGraphRAGï¼ˆå›¾æ£€ç´¢å¢å¼ºç”Ÿæˆï¼‰æŠ€æœ¯ï¼Œç»“åˆNeo4jçŸ¥è¯†å›¾è°±å’Œé€šä¹‰åƒé—®LLM
"""
import logging
from flask import Blueprint, request, g
from werkzeug.utils import secure_filename
from algo.knowledge_graph.graph_retriever import graph_retriever
from algo.llm.text_analysis import TextAnalysis
# from algo.llm.image_understanding import image_understanding
from clients.file_client import file_client
# from services.plant_disease_service import plant_disease_service
# from services.disease_case_service import disease_case_service
# æš‚æ—¶æ³¨é‡Šæ‰æ¤ç‰©ç—…å®³æœåŠ¡ï¼Œæ›¿æ¢ä¸ºæ•™åŠ¡å’¨è¯¢æœåŠ¡
from services.academic_info_service import academic_info_service
from services.academic_case_service import academic_case_service
from utils.response import success, error
from utils.db import db
from utils.jwt_util import token_required
from utils.security_utils import get_current_user, is_admin
from config import TEMP_DIR
import os
# import cv2
# import numpy as np
import re
import json
import uuid
from typing import List, Dict, Any

# é…ç½®æ—¥å¿—
logger = logging.getLogger(__name__)

qa_bp = Blueprint('qa', __name__, url_prefix='/api/qa')
# é˜²ç¯¡æ”¹é”šç‚¹Â·YÃ¡ngYÃ¡ngå°æ ˆåŸåˆ› 2025ï¼Œæœªç»ä¹¦é¢æˆæƒï¼Œè¯·å‹¿å¤åˆ¶ã€‚ğŸ›¡ï¸

# ==================== å…¨å±€é…ç½® ====================
# é—®ç­”æ¨¡å—å›¾ç‰‡å­˜å‚¨æ¡¶åç§°ï¼ˆç”¨äºå­˜å‚¨é—®ç­”å†å²ä¸­å¼•ç”¨çš„å›¾ç‰‡å¿«ç…§ï¼‰
QA_IMAGES_BUCKET = 'qa-history-images'


def _truncate_text(text: str, length: int = 120) -> str:
    if not text:
        return ''
    text = str(text).strip()
    return text if len(text) <= length else text[:length] + '...'


def _format_datetime(value) -> str:
    if not value:
        return 'æœªçŸ¥'
    value_str = str(value).strip()
    if not value_str:
        return 'æœªçŸ¥'
    return value_str[:16]


def _delete_qa_images_from_records(qa_records: List[Dict[str, Any]]) -> None:
    """
    åˆ é™¤é—®ç­”è®°å½•ä¸­è½¬å­˜çš„å›¾ç‰‡

    Args:
        qa_records: é—®ç­”å†å²è®°å½•åˆ—è¡¨
    """
    deleted_count = 0
    failed_count = 0
    skipped_count = 0

    logger.debug(f"[è°ƒè¯•] å¼€å§‹å¤„ç† {len(qa_records)} æ¡é—®ç­”è®°å½•")

    for record in qa_records:
        # 1. åˆ é™¤ç”¨æˆ·ä¸Šä¼ çš„é—®é¢˜å›¾ç‰‡
        if record.get('image_bucket') and record.get('image_object_key'):
            logger.debug(f"[è°ƒè¯•] ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡ - bucket: {record['image_bucket']}, æœŸæœ›bucket: {QA_IMAGES_BUCKET}")
            # åªåˆ é™¤è½¬å­˜åˆ°QA_IMAGES_BUCKETçš„å›¾ç‰‡
            if record['image_bucket'] == QA_IMAGES_BUCKET:
                try:
                    logger.info(f"[å›¾ç‰‡åˆ é™¤] åˆ é™¤ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡: {record['image_bucket']}/{record['image_object_key']}")
                    file_client.delete(record['image_bucket'], record['image_object_key'])
                    deleted_count += 1
                except Exception as e:
                    logger.warning(f"[è­¦å‘Š] åˆ é™¤ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡å¤±è´¥: {str(e)}")
                    failed_count += 1
            else:
                logger.info(f"[è·³è¿‡] ç”¨æˆ·ä¸Šä¼ å›¾ç‰‡ä¸åœ¨QAå­˜å‚¨æ¡¶ä¸­: {record['image_bucket']}/{record['image_object_key']}")
                skipped_count += 1

        # 2. åˆ é™¤æ•™åŠ¡ä¿¡æ¯ä¸­è½¬å­˜çš„å›¾ç‰‡
        if record.get('disease_info_matches'):
            try:
                academic_info_matches = json.loads(record['disease_info_matches'])
                logger.debug(f"[è°ƒè¯•] academic_info_matchesè§£ææˆåŠŸï¼Œå…± {len(academic_info_matches) if isinstance(academic_info_matches, list) else 0} æ¡")
                if isinstance(academic_info_matches, list):
                    for idx, academic_info in enumerate(academic_info_matches):
                        if not isinstance(academic_info, dict):
                            continue

                        bucket = academic_info.get('image_bucket')
                        object_key = academic_info.get('image_object_key')

                        logger.debug(f"[è°ƒè¯•] æ•™åŠ¡ä¿¡æ¯[{idx}] - bucket: {bucket}, æœŸæœ›bucket: {QA_IMAGES_BUCKET}")

                        # åªåˆ é™¤è½¬å­˜åˆ°QA_IMAGES_BUCKETçš„å›¾ç‰‡
                        if bucket == QA_IMAGES_BUCKET and object_key:
                            try:
                                logger.info(f"[å›¾ç‰‡åˆ é™¤] åˆ é™¤æ•™åŠ¡ä¿¡æ¯å›¾ç‰‡: {bucket}/{object_key}")
                                file_client.delete(bucket, object_key)
                                deleted_count += 1
                            except Exception as e:
                                logger.warning(f"[è­¦å‘Š] åˆ é™¤æ•™åŠ¡ä¿¡æ¯å›¾ç‰‡å¤±è´¥: {str(e)}")
                                failed_count += 1
                        elif bucket and object_key:
                            logger.info(f"[è·³è¿‡] æ•™åŠ¡ä¿¡æ¯å›¾ç‰‡ä¸åœ¨QAå­˜å‚¨æ¡¶ä¸­: {bucket}/{object_key}")
                            skipped_count += 1
            except Exception as e:
                logger.warning(f"[è­¦å‘Š] è§£æacademic_info_matcheså¤±è´¥: {str(e)}")

        # 3. åˆ é™¤æ•™åŠ¡æ¡ˆä¾‹ä¸­è½¬å­˜çš„å›¾ç‰‡
        if record.get('disease_case_matches'):
            try:
                academic_case_matches = json.loads(record['disease_case_matches'])
                logger.debug(f"[è°ƒè¯•] academic_case_matchesè§£ææˆåŠŸï¼Œå…± {len(academic_case_matches) if isinstance(academic_case_matches, list) else 0} æ¡")
                if isinstance(academic_case_matches, list):
                    for case_idx, case in enumerate(academic_case_matches):
                        if not isinstance(case, dict):
                            continue

                        images = case.get('images', [])
                        logger.debug(f"[è°ƒè¯•] æ•™åŠ¡æ¡ˆä¾‹[{case_idx}] '{case.get('case_title')}' - {len(images) if isinstance(images, list) else 0} å¼ å›¾ç‰‡")
                        if isinstance(images, list):
                            for img_idx, img in enumerate(images):
                                if not isinstance(img, dict):
                                    continue

                                bucket = img.get('bucket')
                                object_key = img.get('object_key')

                                logger.debug(f"[è°ƒè¯•] æ¡ˆä¾‹å›¾ç‰‡[{img_idx}] - bucket: {bucket}, æœŸæœ›bucket: {QA_IMAGES_BUCKET}")

                                # åªåˆ é™¤è½¬å­˜åˆ°QA_IMAGES_BUCKETçš„å›¾ç‰‡
                                if bucket == QA_IMAGES_BUCKET and object_key:
                                    try:
                                        logger.info(f"[å›¾ç‰‡åˆ é™¤] åˆ é™¤æ•™åŠ¡æ¡ˆä¾‹å›¾ç‰‡: {bucket}/{object_key}")
                                        file_client.delete(bucket, object_key)
                                        deleted_count += 1
                                    except Exception as e:
                                        logger.warning(f"[è­¦å‘Š] åˆ é™¤æ•™åŠ¡æ¡ˆä¾‹å›¾ç‰‡å¤±è´¥: {str(e)}")
                                        failed_count += 1
                                elif bucket and object_key:
                                    logger.info(f"[è·³è¿‡] æ•™åŠ¡æ¡ˆä¾‹å›¾ç‰‡ä¸åœ¨QAå­˜å‚¨æ¡¶ä¸­: {bucket}/{object_key}")
                                    skipped_count += 1
            except Exception as e:
                logger.warning(f"[è­¦å‘Š] è§£æacademic_case_matcheså¤±è´¥: {str(e)}")

    logger.info(f"[å›¾ç‰‡åˆ é™¤å®Œæˆ] æˆåŠŸåˆ é™¤ {deleted_count} å¼ ï¼Œå¤±è´¥ {failed_count} å¼ ï¼Œè·³è¿‡ {skipped_count} å¼ ")


def _copy_images_to_qa_storage(academic_info_matches: List[Dict[str, Any]],
                                academic_case_matches: List[Dict[str, Any]]) -> tuple:
    """
    å°†æ•™åŠ¡ä¿¡æ¯å’Œæ¡ˆä¾‹ä¸­çš„å›¾ç‰‡è½¬å­˜åˆ°é—®ç­”å†å²å›¾ç‰‡å­˜å‚¨æ¡¶

    Args:
        academic_info_matches: æ•™åŠ¡ä¿¡æ¯åˆ—è¡¨
        academic_case_matches: æ•™åŠ¡æ¡ˆä¾‹åˆ—è¡¨

    Returns:
        tuple: (æ›´æ–°åçš„æ•™åŠ¡ä¿¡æ¯åˆ—è¡¨, æ›´æ–°åçš„æ¡ˆä¾‹åˆ—è¡¨)
    """
    # è½¬å­˜æ•™åŠ¡ä¿¡æ¯å›¾ç‰‡
    for academic_info in academic_info_matches:
        if academic_info.get('image_bucket') and academic_info.get('image_object_key'):
            try:
                logger.info(f"[å›¾ç‰‡è½¬å­˜] è½¬å­˜æ•™åŠ¡ä¿¡æ¯å›¾ç‰‡: {academic_info.get('name')}")

                # ä¸‹è½½åŸå›¾ç‰‡å†…å®¹
                image_content = file_client.get(
                    academic_info['image_bucket'],
                    academic_info['image_object_key']
                )

                # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                original_filename = academic_info['image_object_key'].split('/')[-1]
                file_ext = os.path.splitext(original_filename)[1] or '.jpg'
                temp_filename = f"qa_academic_{uuid.uuid4().hex}{file_ext}"
                temp_path = os.path.join(TEMP_DIR, temp_filename)

                # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                with open(temp_path, 'wb') as f:
                    f.write(image_content)

                try:
                    # ä¸Šä¼ åˆ°é—®ç­”å†å²å›¾ç‰‡å­˜å‚¨æ¡¶
                    upload_result = file_client.upload(QA_IMAGES_BUCKET, temp_path, is_cache=False)

                    # æ›´æ–°å›¾ç‰‡ä¿¡æ¯
                    academic_info['image_bucket'] = upload_result['bucket']
                    academic_info['image_object_key'] = upload_result['objectKey']
                    academic_info['imageUrl'] = upload_result['url']

                    logger.info(f"[å›¾ç‰‡è½¬å­˜] æ•™åŠ¡ä¿¡æ¯å›¾ç‰‡è½¬å­˜æˆåŠŸ: {upload_result['url']}")
                finally:
                    # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                    if os.path.exists(temp_path):
                        os.remove(temp_path)

            except Exception as e:
                logger.error(f"[é”™è¯¯] æ•™åŠ¡ä¿¡æ¯å›¾ç‰‡è½¬å­˜å¤±è´¥ï¼Œæ¸…ç©ºå›¾ç‰‡ä¿¡æ¯: {str(e)}")
                # è½¬å­˜å¤±è´¥åˆ™æ¸…ç©ºå›¾ç‰‡å­—æ®µ
                academic_info['image_bucket'] = None
                academic_info['image_object_key'] = None
                academic_info['imageUrl'] = None

    # è½¬å­˜æ•™åŠ¡æ¡ˆä¾‹å›¾ç‰‡
    for case in academic_case_matches:
        images_field = case.get('images')

        # å…¼å®¹å­—ç¬¦ä¸²å­˜å‚¨çš„åœºæ™¯
        if isinstance(images_field, str):
            try:
                images_field = json.loads(images_field)
            except Exception:
                images_field = []

        if not isinstance(images_field, list) or not images_field:
            case['images'] = []
            continue

        try:
            new_images = []

            for img in images_field:
                if not isinstance(img, dict):
                    continue

                bucket = img.get('bucket')
                object_key = img.get('object_key') or img.get('objectKey')

                if not bucket or not object_key:
                    continue

                try:
                    logger.info(f"[å›¾ç‰‡è½¬å­˜] è½¬å­˜æ¡ˆä¾‹å›¾ç‰‡: {case.get('case_title')} - åŸbucket: {bucket}, åŸobject_key: {object_key}")

                    # ä¸‹è½½åŸå›¾ç‰‡å†…å®¹
                    image_content = file_client.get(bucket, object_key)
                    logger.debug(f"[å›¾ç‰‡è½¬å­˜] å›¾ç‰‡ä¸‹è½½æˆåŠŸï¼Œå¤§å°: {len(image_content)} bytes")

                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                    original_filename = object_key.split('/')[-1]
                    file_ext = os.path.splitext(original_filename)[1] or '.jpg'
                    temp_filename = f"qa_case_{uuid.uuid4().hex}{file_ext}"
                    temp_path = os.path.join(TEMP_DIR, temp_filename)

                    # ä¿å­˜åˆ°ä¸´æ—¶æ–‡ä»¶
                    with open(temp_path, 'wb') as f:
                        f.write(image_content)

                    try:
                        # ä¸Šä¼ åˆ°é—®ç­”å†å²å›¾ç‰‡å­˜å‚¨æ¡¶
                        upload_result = file_client.upload(QA_IMAGES_BUCKET, temp_path, is_cache=False)

                        # æ·»åŠ æ–°çš„å›¾ç‰‡ä¿¡æ¯ï¼ˆåªä¿ç•™bucketå’Œobject_keyï¼Œä¸åŒ…å«urlï¼‰
                        new_images.append({
                            'bucket': upload_result['bucket'],
                            'object_key': upload_result['objectKey']
                        })

                        logger.info(f"[å›¾ç‰‡è½¬å­˜] æ¡ˆä¾‹å›¾ç‰‡è½¬å­˜æˆåŠŸ")
                        logger.debug(f"  æ–°bucket: {upload_result['bucket']}, æ–°object_key: {upload_result['objectKey']}")
                    finally:
                        # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                        if os.path.exists(temp_path):
                            os.remove(temp_path)

                except Exception as e:
                    logger.error(f"[é”™è¯¯] æ¡ˆä¾‹å›¾ç‰‡è½¬å­˜å¤±è´¥ï¼Œè·³è¿‡è¯¥å›¾ç‰‡: {str(e)}")
                    logger.error(f"  å¤±è´¥çš„å›¾ç‰‡: bucket={bucket}, object_key={object_key}")
                    # è½¬å­˜å¤±è´¥ç›´æ¥è·³è¿‡ï¼Œä¸æ·»åŠ åˆ°ç»“æœä¸­
                    continue

            # æ›´æ–°æ¡ˆä¾‹çš„å›¾ç‰‡ä¿¡æ¯ï¼ˆä¸å†åŒ…å«imageUrlsï¼‰
            case['images'] = new_images
            logger.info(f"[å›¾ç‰‡è½¬å­˜] æ¡ˆä¾‹ '{case.get('case_title')}' å¤„ç†å®Œæˆï¼Œå…± {len(new_images)} å¼ å›¾ç‰‡")
            logger.debug(f"  images: {json.dumps(new_images, ensure_ascii=False)}")

        except Exception as e:
            logger.error(f"[é”™è¯¯] æ¡ˆä¾‹å›¾ç‰‡åˆ—è¡¨å¤„ç†å¤±è´¥ï¼Œæ¸…ç©ºå›¾ç‰‡ä¿¡æ¯: {str(e)}")
            import traceback
            traceback.print_exc()
            # å¤„ç†å¤±è´¥åˆ™æ¸…ç©ºå›¾ç‰‡æ•°æ®
            case['images'] = []

    return academic_info_matches, academic_case_matches


# æ›´æ–°ä¸Šä¸‹æ–‡æ„å»ºé€»è¾‘
def build_academic_info_context(academic_matches: List[Dict]) -> str:
    """æ„å»ºæ•™åŠ¡ä¿¡æ¯ä¸Šä¸‹æ–‡"""
    if not academic_matches:
        return ""

    context_parts = ["æ•™åŠ¡ç›¸å…³ä¿¡æ¯ï¼š"]
    for match in academic_matches[:3]:  # é™åˆ¶åŒ¹é…æ•°é‡
        context_parts.append(f"- {match.get('name', '')}: {match.get('description', '')}")

    return "\n".join(context_parts)


def build_academic_case_context(academic_case_matches: List[Dict]) -> str:
    """æ„å»ºæ•™åŠ¡æ¡ˆä¾‹ä¸Šä¸‹æ–‡"""
    if not academic_case_matches:
        return ""

    context_parts = ["ç›¸å…³æ•™åŠ¡æ¡ˆä¾‹ï¼š"]
    for match in academic_case_matches[:2]:
        context_parts.append(
            f"- {match.get('case_title', '')} "
            f"({match.get('case_date', '')}): {match.get('description', '')}"
        )

    return "\n".join(context_parts)




@qa_bp.route('/conversation/list', methods=['GET'])
@token_required
def get_conversation_list():
    """
    è·å–ä¼šè¯åˆ—è¡¨

    Response:
        {
            "code": 200,
            "message": "è·å–æˆåŠŸ",
            "data": [
                {
                    "id": 1,
                    "title": "å‘åŠ¨æœºç»´æŠ¤å’¨è¯¢",
                    "create_time": "2025-01-01 10:00:00",
                    "update_time": "2025-01-01 11:00:00",
                    "message_count": 5
                }
            ]
        }
    """
    try:
        user = get_current_user()
        user_id = user.id

        # æŸ¥è¯¢ç”¨æˆ·çš„æ‰€æœ‰ä¼šè¯
        sql = """
        SELECT
            c.id, c.title, c.create_time, c.update_time,
            COUNT(q.id) as message_count
        FROM conversation c
        LEFT JOIN qa_history q ON c.id = q.conversation_id
        WHERE c.user_id = ?
        GROUP BY c.id
        ORDER BY c.update_time DESC
        """

        conversations = db.query(sql, (user_id,))

        return success({
            'list': conversations,
            'total': len(conversations)
        }, 'è·å–ä¼šè¯åˆ—è¡¨æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'è·å–ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}')


@qa_bp.route('/conversation/all', methods=['GET'])
@token_required
def get_all_conversations():
    """
    è·å–æ‰€æœ‰ç”¨æˆ·çš„ä¼šè¯åˆ—è¡¨ï¼ˆä»…ç®¡ç†å‘˜ï¼‰
    ç”¨äºç®¡ç†åå°ç»Ÿè®¡

    Response:
        {
            "code": 200,
            "message": "è·å–æˆåŠŸ",
            "data": {
                "list": [...],
                "total": 100
            }
        }
    """
    try:
        # éªŒè¯æ˜¯å¦ä¸ºç®¡ç†å‘˜
        if not is_admin():
            return error('æƒé™ä¸è¶³ï¼Œä»…ç®¡ç†å‘˜å¯è®¿é—®', 403)

        # æŸ¥è¯¢æ‰€æœ‰ä¼šè¯
        sql = """
        SELECT
            c.id, c.title, c.user_id, c.user_name, c.create_time, c.update_time,
            COUNT(q.id) as message_count
        FROM conversation c
        LEFT JOIN qa_history q ON c.id = q.conversation_id
        GROUP BY c.id
        ORDER BY c.update_time DESC
        """

        conversations = db.query(sql)

        return success({
            'list': conversations,
            'total': len(conversations)
        }, 'è·å–æ‰€æœ‰ä¼šè¯åˆ—è¡¨æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] è·å–æ‰€æœ‰ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'è·å–æ‰€æœ‰ä¼šè¯åˆ—è¡¨å¤±è´¥: {str(e)}')


@qa_bp.route('/conversation/create', methods=['POST'])
@token_required
def create_conversation():
    """
    åˆ›å»ºæ–°ä¼šè¯

    Request Body:
        {
            "title": "ä¼šè¯æ ‡é¢˜"  # å¯é€‰ï¼Œé»˜è®¤ä¸º"æ–°ä¼šè¯"
        }

    Response:
        {
            "code": 200,
            "message": "åˆ›å»ºæˆåŠŸ",
            "data": {
                "id": 1,
                "title": "æ–°ä¼šè¯"
            }
        }
    """
    try:
        user = get_current_user()
        user_id = user.id
        user_name = user.username

        data = request.get_json() or {}
        title = data.get('title', 'æ–°ä¼šè¯').strip()

        if not title:
            title = 'æ–°ä¼šè¯'

        # åˆ›å»ºä¼šè¯
        sql = """
        INSERT INTO conversation (title, user_id, user_name)
        VALUES (?, ?, ?)
        """

        db.execute(sql, (title, user_id, user_name))

        # è·å–æ–°åˆ›å»ºçš„ä¼šè¯ID
        conversation_id = db.query("SELECT last_insert_rowid() as id", fetchone=True)['id']

        return success({
            'conversation_id': conversation_id,
            'title': title
        }, 'åˆ›å»ºä¼šè¯æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'åˆ›å»ºä¼šè¯å¤±è´¥: {str(e)}')


@qa_bp.route('/conversation/<int:conversation_id>', methods=['DELETE'])
@token_required
def delete_conversation(conversation_id):
    """
    åˆ é™¤ä¼šè¯ï¼ˆä¼šçº§è”åˆ é™¤ä¼šè¯ä¸­çš„æ‰€æœ‰æ¶ˆæ¯ï¼‰

    Response:
        {
            "code": 200,
            "message": "åˆ é™¤æˆåŠŸ"
        }
    """
    try:
        user = get_current_user()
        user_id = user.id

        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        check_sql = "SELECT user_id FROM conversation WHERE id = ?"
        conversation = db.query(check_sql, (conversation_id,), fetchone=True)

        if not conversation:
            return error('ä¼šè¯ä¸å­˜åœ¨')

        if not is_admin() and conversation['user_id'] != user_id:
            return error('æ— æƒåˆ é™¤æ­¤ä¼šè¯')

        # ç¬¬ä¸€æ­¥ï¼šæŸ¥è¯¢ä¼šè¯ä¸­çš„æ‰€æœ‰é—®ç­”è®°å½•ï¼ˆç”¨äºåˆ é™¤å›¾ç‰‡ï¼‰
        query_sql = """
        SELECT id, image_bucket, image_object_key, disease_info_matches, disease_case_matches
        FROM qa_history
        WHERE conversation_id = ?
        """
        qa_records = db.query(query_sql, (conversation_id,))

        # ç¬¬äºŒæ­¥ï¼šåˆ é™¤è½¬å­˜çš„å›¾ç‰‡
        if qa_records:
            logger.info(f"[åˆ é™¤ä¼šè¯] ä¼šè¯{conversation_id}åŒ…å«{len(qa_records)}æ¡è®°å½•ï¼Œå¼€å§‹åˆ é™¤è½¬å­˜å›¾ç‰‡")
            _delete_qa_images_from_records(qa_records)
        else:
            logger.info(f"[åˆ é™¤ä¼šè¯] ä¼šè¯{conversation_id}æ²¡æœ‰é—®ç­”è®°å½•")

        # ç¬¬ä¸‰æ­¥ï¼šåˆ é™¤æ•°æ®åº“è®°å½•
        db.execute("DELETE FROM qa_history WHERE conversation_id = ?", (conversation_id,))
        delete_sql = "DELETE FROM conversation WHERE id = ?"
        db.execute(delete_sql, (conversation_id,))

        return success(None, 'åˆ é™¤ä¼šè¯æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'åˆ é™¤ä¼šè¯å¤±è´¥: {str(e)}')


@qa_bp.route('/conversation/<int:conversation_id>/rename', methods=['PUT'])
@token_required
def rename_conversation(conversation_id):
    """
    é‡å‘½åä¼šè¯

    Request Body:
        {
            "title": "æ–°æ ‡é¢˜"
        }

    Response:
        {
            "code": 200,
            "message": "é‡å‘½åæˆåŠŸ"
        }
    """
    try:
        user = get_current_user()
        user_id = user.id

        data = request.get_json()
        if not data or not data.get('title'):
            return error('è¯·æä¾›æ–°æ ‡é¢˜')

        title = data.get('title').strip()
        if not title:
            return error('æ ‡é¢˜ä¸èƒ½ä¸ºç©º')

        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        check_sql = "SELECT user_id FROM conversation WHERE id = ?"
        conversation = db.query(check_sql, (conversation_id,), fetchone=True)

        if not conversation:
            return error('ä¼šè¯ä¸å­˜åœ¨')

        if not is_admin() and conversation['user_id'] != user_id:
            return error('æ— æƒä¿®æ”¹æ­¤ä¼šè¯')

        # æ›´æ–°ä¼šè¯æ ‡é¢˜
        update_sql = """
        UPDATE conversation
        SET title = ?, update_time = CURRENT_TIMESTAMP
        WHERE id = ?
        """
        db.execute(update_sql, (title, conversation_id))

        return success(None, 'é‡å‘½åæˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] é‡å‘½åä¼šè¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'é‡å‘½åä¼šè¯å¤±è´¥: {str(e)}')


@qa_bp.route('/conversation/<int:conversation_id>/messages', methods=['GET'])
@token_required
def get_conversation_messages(conversation_id):
    """
    è·å–ä¼šè¯ä¸­çš„æ‰€æœ‰æ¶ˆæ¯

    Response:
        {
            "code": 200,
            "message": "è·å–æˆåŠŸ",
            "data": [
                {
                    "id": 1,
                    "question": "é—®é¢˜",
                    "answer": "ç­”æ¡ˆ",
                    "related_entities": [],
                    "create_time": "2025-01-01 10:00:00"
                }
            ]
        }
    """
    try:
        user = get_current_user()
        user_id = user.id

        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        check_sql = "SELECT user_id FROM conversation WHERE id = ?"
        conversation = db.query(check_sql, (conversation_id,), fetchone=True)

        if not conversation:
            return error('ä¼šè¯ä¸å­˜åœ¨')

        if not is_admin() and conversation['user_id'] != user_id:
            return error('æ— æƒè®¿é—®æ­¤ä¼šè¯')

        # è·å–ä¼šè¯ä¸­çš„æ‰€æœ‰æ¶ˆæ¯
        messages_sql = """
        SELECT id, question, answer, related_entities, graph_context,
               disease_info_matches, disease_case_matches, keywords,
               image_url, create_time
        FROM qa_history
        WHERE conversation_id = ?
        ORDER BY create_time ASC
        """

        messages = db.query(messages_sql, (conversation_id,))

        # è§£æ JSONå­—æ®µ
        for msg in messages:
            try:
                related_entities_str = msg.get('related_entities', '[]')
                msg['related_entities'] = json.loads(related_entities_str) if related_entities_str else []
            except:
                msg['related_entities'] = []

            try:
                info_str = msg.get('disease_info_matches', '[]')
                msg['academic_info_matches'] = json.loads(info_str) if info_str else []
            except:
                msg['academic_info_matches'] = []

            try:
                case_str = msg.get('disease_case_matches', '[]')
                msg['academic_case_matches'] = json.loads(case_str) if case_str else []
            except:
                msg['academic_case_matches'] = []

            try:
                keywords_str = msg.get('keywords', '[]')
                parsed_keywords = json.loads(keywords_str) if keywords_str else []
                msg['keywords'] = parsed_keywords if isinstance(parsed_keywords, list) else []
            except:
                msg['keywords'] = []

            # graph_context å·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œæ— éœ€è§£æ
            if not msg.get('graph_context'):
                msg['graph_context'] = ''
            if msg['academic_info_matches']:
                msg['academic_info_context'] = build_academic_info_context(msg['academic_info_matches'])
            else:
                msg['academic_info_context'] = ''

            if msg['academic_case_matches']:
                msg['academic_case_context'] = build_academic_case_context(msg['academic_case_matches'])
            else:
                msg['academic_case_context'] = ''

        return success({
            'list': messages,
            'total': len(messages)
        }, 'è·å–æ¶ˆæ¯æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] è·å–ä¼šè¯æ¶ˆæ¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'è·å–ä¼šè¯æ¶ˆæ¯å¤±è´¥: {str(e)}')


@qa_bp.route('/conversation/<int:conversation_id>/messages', methods=['DELETE'])
@token_required
def clear_conversation_messages(conversation_id):
    """
    æ¸…é™¤ä¼šè¯çš„æ‰€æœ‰æ¶ˆæ¯è®°å½•

    Response:
        {
            "code": 200,
            "message": "æ¸…é™¤æˆåŠŸ"
        }
    """
    try:
        user = get_current_user()
        user_id = user.id

        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        check_sql = "SELECT user_id FROM conversation WHERE id = ?"
        conversation = db.query(check_sql, (conversation_id,), fetchone=True)

        if not conversation:
            return error('ä¼šè¯ä¸å­˜åœ¨')

        if not is_admin() and conversation['user_id'] != user_id:
            return error('æ— æƒæ¸…é™¤æ­¤ä¼šè¯çš„æ¶ˆæ¯')

        # ç¬¬ä¸€æ­¥ï¼šæŸ¥è¯¢ä¼šè¯ä¸­çš„æ‰€æœ‰é—®ç­”è®°å½•ï¼ˆç”¨äºåˆ é™¤å›¾ç‰‡ï¼‰
        query_sql = """
        SELECT id, image_bucket, image_object_key, disease_info_matches, disease_case_matches
        FROM qa_history
        WHERE conversation_id = ?
        """
        qa_records = db.query(query_sql, (conversation_id,))

        # ç¬¬äºŒæ­¥ï¼šåˆ é™¤è½¬å­˜çš„å›¾ç‰‡
        if qa_records:
            logger.info(f"[æ¸…é™¤æ¶ˆæ¯] ä¼šè¯{conversation_id}åŒ…å«{len(qa_records)}æ¡è®°å½•ï¼Œå¼€å§‹åˆ é™¤è½¬å­˜å›¾ç‰‡")
            _delete_qa_images_from_records(qa_records)
        else:
            logger.info(f"[æ¸…é™¤æ¶ˆæ¯] ä¼šè¯{conversation_id}æ²¡æœ‰é—®ç­”è®°å½•")

        # ç¬¬ä¸‰æ­¥ï¼šåˆ é™¤æ•°æ®åº“è®°å½•
        delete_sql = "DELETE FROM qa_history WHERE conversation_id = ?"
        deleted_count = db.execute(delete_sql, (conversation_id,))

        logger.info(f"[æ¸…é™¤æˆåŠŸ] ä¼šè¯{conversation_id}å…±æ¸…é™¤{deleted_count}æ¡æ¶ˆæ¯")
        return success(None, f'æ¸…é™¤æˆåŠŸ,å…±åˆ é™¤{deleted_count}æ¡æ¶ˆæ¯')

    except Exception as e:
        logger.error(f"[é”™è¯¯] æ¸…é™¤ä¼šè¯æ¶ˆæ¯å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'æ¸…é™¤ä¼šè¯æ¶ˆæ¯å¤±è´¥: {str(e)}')


@qa_bp.route('/conversation/<int:conversation_id>/generate-title', methods=['POST'])
@token_required
def generate_conversation_title(conversation_id):
    """
    æ ¹æ®ä¼šè¯èŠå¤©è®°å½•è‡ªåŠ¨ç”Ÿæˆæ ‡é¢˜

    Response:
        {
            "code": 200,
            "message": "æ ‡é¢˜ç”ŸæˆæˆåŠŸ",
            "data": {
                "title": "ç”Ÿæˆçš„æ ‡é¢˜"
            }
        }
    """
    try:
        user = get_current_user()
        user_id = user.id

        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        check_sql = "SELECT user_id, title FROM conversation WHERE id = ?"
        conversation = db.query(check_sql, (conversation_id,), fetchone=True)

        if not conversation:
            return error('ä¼šè¯ä¸å­˜åœ¨')

        if not is_admin() and conversation['user_id'] != user_id:
            return error('æ— æƒä¿®æ”¹æ­¤ä¼šè¯')

        # è·å–è¯¥ä¼šè¯çš„æœ€è¿‘å‡ æ¡æ¶ˆæ¯ï¼ˆæœ€å¤š3è½®å¯¹è¯ï¼Œå³6æ¡æ¶ˆæ¯ï¼‰
        messages_sql = """
        SELECT question, answer
        FROM qa_history
        WHERE conversation_id = ?
        ORDER BY create_time ASC
        LIMIT 6
        """
        messages = db.query(messages_sql, (conversation_id,))

        if not messages or len(messages) == 0:
            return error('ä¼šè¯æ²¡æœ‰æ¶ˆæ¯è®°å½•ï¼Œæ— æ³•ç”Ÿæˆæ ‡é¢˜')

        # æ„å»ºå¯¹è¯å†…å®¹ç”¨äºç”Ÿæˆæ ‡é¢˜
        conversation_context = []
        for msg in messages:
            conversation_context.append(f"ç”¨æˆ·: {msg['question']}")
            conversation_context.append(f"AI: {msg['answer'][:200]}")  # é™åˆ¶é•¿åº¦

        context_text = "\n".join(conversation_context)

        # ä½¿ç”¨LLMç”Ÿæˆæ ‡é¢˜
        logger.info(f"[æ ‡é¢˜ç”Ÿæˆ] å¼€å§‹ä¸ºä¼šè¯{conversation_id}ç”Ÿæˆæ ‡é¢˜...")

        title_prompt = f"""è¯·æ ¹æ®ä»¥ä¸‹å¯¹è¯å†…å®¹ï¼Œç”Ÿæˆä¸€ä¸ªç®€æ´çš„ä¼šè¯æ ‡é¢˜ï¼ˆ8-15å­—ï¼‰ã€‚

å¯¹è¯å†…å®¹ï¼š
{context_text}

è¦æ±‚ï¼š
1. æ ‡é¢˜è¦ç®€æ´æ˜äº†ï¼Œ8-15ä¸ªå­—
2. èƒ½å¤Ÿå‡†ç¡®æ¦‚æ‹¬å¯¹è¯çš„æ ¸å¿ƒä¸»é¢˜
3. åªè¾“å‡ºæ ‡é¢˜å†…å®¹ï¼Œä¸è¦æœ‰ä»»ä½•å…¶ä»–è¯´æ˜æ–‡å­—
4. ä¸è¦åŒ…å«"ä¼šè¯"ã€"å¯¹è¯"ç­‰è¯è¯­

æ ‡é¢˜ï¼š"""

        llm = TextAnalysis()
        title_result = llm.send_message(title_prompt, "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ ‡é¢˜ç”ŸæˆåŠ©æ‰‹ã€‚")

        if not title_result.get('success'):
            return error(f"æ ‡é¢˜ç”Ÿæˆå¤±è´¥: {title_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        generated_title = title_result.get('result', '').strip()

        # æ¸…ç†æ ‡é¢˜ï¼ˆç§»é™¤å¯èƒ½çš„å¼•å·ã€å†’å·ç­‰ï¼‰
        generated_title = generated_title.replace('"', '').replace("'", '').replace(':', '').replace('ï¼š', '')

        # é™åˆ¶æ ‡é¢˜é•¿åº¦
        if len(generated_title) > 30:
            generated_title = generated_title[:30]

        if not generated_title:
            return error('ç”Ÿæˆçš„æ ‡é¢˜ä¸ºç©ºï¼Œè¯·é‡è¯•')

        # æ›´æ–°ä¼šè¯æ ‡é¢˜
        update_sql = "UPDATE conversation SET title = ?, update_time = CURRENT_TIMESTAMP WHERE id = ?"
        db.execute(update_sql, (generated_title, conversation_id))

        logger.info(f"[æ ‡é¢˜ç”Ÿæˆ] æˆåŠŸä¸ºä¼šè¯{conversation_id}ç”Ÿæˆæ ‡é¢˜: {generated_title}")

        return success({'title': generated_title}, 'æ ‡é¢˜ç”ŸæˆæˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] ç”Ÿæˆä¼šè¯æ ‡é¢˜å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'ç”Ÿæˆä¼šè¯æ ‡é¢˜å¤±è´¥: {str(e)}')


@qa_bp.route('/ask', methods=['POST'])
@token_required
def ask_question():
    """
    æ™ºèƒ½é—®ç­”æ¥å£ï¼ˆæ”¯æŒå¤šè½®å¯¹è¯+ä¼šè¯ç®¡ç†+çŸ¥è¯†å›¾è°±æ£€ç´¢ï¼‰

    Request Body:
        {
            "question": "ç”¨æˆ·é—®é¢˜",
            "conversation_id": 1,  # å¿…å¡«ï¼Œæ‰€å±ä¼šè¯ID
            "top_k": 10,  # å¯é€‰ï¼Œæ£€ç´¢çš„ç›¸å…³å®ä½“æ•°é‡ï¼Œé»˜è®¤10
            "history": [  # å¯é€‰ï¼Œå¯¹è¯å†å²ï¼ˆæœ€è¿‘Nè½®ï¼‰
                {"role": "user", "content": "ä¹‹å‰çš„é—®é¢˜"},
                {"role": "assistant", "content": "ä¹‹å‰çš„å›ç­”"}
            ]
        }

    Response:
        {
            "code": 200,
            "message": "å›ç­”æˆåŠŸ",
            "data": {
                "question": "ç”¨æˆ·é—®é¢˜",
                "answer": "AIç”Ÿæˆçš„ç­”æ¡ˆ",
                "related_entities": [...]  // ç›¸å…³çŸ¥è¯†å›¾è°±å®ä½“åˆ—è¡¨
                "graph_context": "..."  // å›¾è°±ä¸Šä¸‹æ–‡ä¿¡æ¯
            }
        }
    """
    try:
        import time
        # è®°å½•è¯·æ±‚å¼€å§‹æ—¶é—´
        start_time = time.time()
        
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
        user = get_current_user()
        user_id = user.id
        user_name = user.username
        
        # åˆ¤æ–­è¯·æ±‚ç±»å‹(form-dataæˆ–json)
        if request.content_type and 'multipart/form-data' in request.content_type:
            # è¡¨å•æ•°æ®(åŒ…å«å›¾ç‰‡)
            question = request.form.get('question', '').strip()
            conversation_id = request.form.get('conversation_id')
            if conversation_id:
                conversation_id = int(conversation_id)
            top_k = int(request.form.get('top_k', 10))

            # è§£æhistory
            history_str = request.form.get('history', '[]')
            history = json.loads(history_str) if history_str else []

            # è·å–å›¾ç‰‡æ–‡ä»¶
            image_file = request.files.get('image')
        else:
            # JSONæ•°æ®(çº¯æ–‡å­—)
            data = request.get_json()
            question = data.get('question', '').strip()
            conversation_id = data.get('conversation_id')
            top_k = data.get('top_k', 10)
            history = data.get('history', [])
            image_file = None

        # è®°å½•è¯·æ±‚ä¿¡æ¯
        logger.info(f"[è¯·æ±‚] ç”¨æˆ· {user_id} å‘èµ·èŠå¤©è¯·æ±‚ï¼Œé—®é¢˜ï¼š{question[:100]}...")

        # å‚æ•°æ ¡éªŒ
        if not question:
            return error('é—®é¢˜ä¸èƒ½ä¸ºç©º')

        if not conversation_id:
            return error('conversation_idä¸èƒ½ä¸ºç©º')

        if top_k < 1 or top_k > 20:
            return error('top_kå‚æ•°å¿…é¡»åœ¨1-20ä¹‹é—´')

        # æ ¡éªŒå†å²è®°å½•æ ¼å¼
        if history and not isinstance(history, list):
            return error('historyå‚æ•°å¿…é¡»æ˜¯æ•°ç»„')

        # æ£€æŸ¥ä¼šè¯æ˜¯å¦å­˜åœ¨ä¸”å±äºå½“å‰ç”¨æˆ·
        check_sql = "SELECT user_id FROM conversation WHERE id = ?"
        conversation = db.query(check_sql, (conversation_id,), fetchone=True)

        if not conversation:
            return error('ä¼šè¯ä¸å­˜åœ¨')

        if conversation['user_id'] != user_id:
            return error('æ— æƒè®¿é—®æ­¤ä¼šè¯')

        # å¤„ç†å›¾ç‰‡(å¦‚æœæœ‰)
        image_analysis_result = None
        image_bucket = None
        image_object_key = None
        image_url = None

        if image_file:
            logger.info(f"[å›¾ç‰‡] æ¥æ”¶åˆ°å›¾ç‰‡: {image_file.filename}")

            # ä¿å­˜ä¸´æ—¶æ–‡ä»¶
            filename = secure_filename(image_file.filename)
            temp_path = os.path.join(TEMP_DIR, filename)
            image_file.save(temp_path)

            try:
                # è¯»å–å›¾ç‰‡
                # image_np = cv2.imread(temp_path)
                # if image_np is None:
                #     return error('å›¾ç‰‡æ ¼å¼ä¸æ”¯æŒæˆ–æ–‡ä»¶æŸå')

                # æš‚æ—¶æ³¨é‡Šå›¾ç‰‡åˆ†æåŠŸèƒ½
                # print(f"[å›¾ç‰‡ç†è§£] å¼€å§‹åˆ†æå›¾ç‰‡")
                # prompt = f"è¯·è¯¦ç»†åˆ†æè¿™å¼ æ•™åŠ¡ç›¸å…³å›¾ç‰‡ï¼Œæè¿°ä½ çœ‹åˆ°çš„å†…å®¹ã€åŒ…å«çš„ä¿¡æ¯ç­‰ï¼Œå¹¶ç»“åˆç”¨æˆ·é—®é¢˜ç»™å‡ºåˆæ­¥åˆ¤æ–­ã€‚\n\nç”¨æˆ·é—®é¢˜ï¼š{question}"
                # analysis = image_understanding.analyze_image(image_np, prompt)

                # if not analysis['success']:
                #     return error(f'å›¾ç‰‡åˆ†æå¤±è´¥: {analysis.get("error", "æœªçŸ¥é”™è¯¯")}')

                # image_analysis_result = analysis['result']
                # print(f"[å›¾ç‰‡ç†è§£] åˆ†æç»“æœ: {image_analysis_result[:200]}...")
                image_analysis_result = "[å›¾ç‰‡åˆ†æåŠŸèƒ½æš‚ä¸å¯ç”¨]"

                # ä¸Šä¼ å›¾ç‰‡åˆ°æ–‡ä»¶æœåŠ¡å™¨
                logger.info(f"[æ–‡ä»¶ä¸Šä¼ ] ä¸Šä¼ å›¾ç‰‡åˆ°æ–‡ä»¶æœåŠ¡å™¨")
                upload_result = file_client.upload(QA_IMAGES_BUCKET, temp_path, is_cache=False)
                image_bucket = upload_result['bucket']
                image_object_key = upload_result['objectKey']
                image_url = upload_result['url']
                logger.info(f"[æ–‡ä»¶ä¸Šä¼ ] å›¾ç‰‡URL: {image_url}")
            except Exception as e:
                logger.error(f"[é”™è¯¯] å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
                import traceback
                traceback.print_exc()
                return error(f'å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}')
            finally:
                # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
                if os.path.exists(temp_path):
                    os.remove(temp_path)

        # ç¬¬ä¸€æ­¥ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦RAGæ£€ç´¢
        # æ™ºèƒ½æ„å›¾è¯†åˆ«æ¨¡å— - ç¾Šå°æ ˆ Original Algorithm Â© 2025
        # åŸºäºä¸Šä¸‹æ–‡åˆ†æçš„RAGæ£€ç´¢å†³ç­–ç³»ç»Ÿï¼Œä¼˜åŒ–æŸ¥è¯¢æ•ˆç‡ä¸å“åº”å‡†ç¡®åº¦
        # å¦‚æœä¸Šä¼ äº†å›¾ç‰‡ï¼Œè·³è¿‡RAGæ£€ç´¢ï¼Œç›´æ¥ä½¿ç”¨å›¾ç‰‡ç†è§£ç»“æœ
        if image_analysis_result:
            logger.info("[å›¾ç‰‡é—®ç­”] æ£€æµ‹åˆ°å›¾ç‰‡ä¸Šä¼ ï¼Œè·³è¿‡RAGæ£€ç´¢ï¼Œç›´æ¥ä½¿ç”¨å›¾ç‰‡ç†è§£")
            need_rag = False
        else:
            # æ„å›¾è¯†åˆ«ï¼šåˆ¤æ–­æ˜¯å¦éœ€è¦RAGæ£€ç´¢
            logger.info(f"[æ„å›¾è¯†åˆ«] é—®é¢˜: {question}")

            # åœ¨æ„å›¾è¯†åˆ«éƒ¨åˆ†æ›´æ–°æç¤ºè¯
            intent_prompt = f"""è¯·åˆ¤æ–­ç”¨æˆ·çš„é—®é¢˜æ˜¯å¦éœ€è¦æŸ¥è¯¢æ•™åŠ¡çŸ¥è¯†å›¾è°±æ¥å›ç­”ã€‚

            ç”¨æˆ·é—®é¢˜ï¼š{question}

            åˆ¤æ–­æ ‡å‡†ï¼š
            1. å¦‚æœæ˜¯æ‰“æ‹›å‘¼ã€é—²èŠã€æ„Ÿè°¢ç­‰æ—¥å¸¸å¯¹è¯ï¼Œè¾“å‡ºï¼šNO
            2. å¦‚æœæ˜¯è¯¢é—®æ•™åŠ¡æ”¿ç­–ã€è¯¾ç¨‹ä¿¡æ¯ã€é€‰è¯¾æŒ‡å¯¼ã€å­¦åˆ†è®¤å®šç­‰ï¼Œè¾“å‡ºï¼šYES
            3. å¦‚æœæ˜¯è¯¢é—®ä¸“ä¸šè¦æ±‚ã€åŸ¹å…»æ–¹æ¡ˆã€è€ƒè¯•å®‰æ’ç­‰ï¼Œè¾“å‡ºï¼šYES
            4. å¦‚æœæ˜¯è¯¢é—®è½¬ä¸“ä¸šè¡¥ä¿®ã€è€ƒè¯•æˆç»©å¤æ ¸æµç¨‹ã€èŒç§°æ™‹å‡å¬è¯¾ç­‰ï¼Œè¾“å‡ºï¼šYES
            5. å¦‚æœç”¨æˆ·æ˜ç¡®è¦æ±‚æ£€ç´¢çŸ¥è¯†ã€æŸ¥è¯¢å›¾è°±ã€æœç´¢èµ„æ–™ç­‰ï¼Œè¾“å‡ºï¼šYES

            åªè¾“å‡º YES æˆ– NOï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""

            llm = TextAnalysis()
            intent_result = llm.send_message(intent_prompt, "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ„å›¾è¯†åˆ«åŠ©æ‰‹ï¼Œåªè¾“å‡ºYESæˆ–NOã€‚")

            need_rag = "YES" in intent_result.get('result', '').upper()
            logger.info(f"[æ„å›¾è¯†åˆ«] æ˜¯å¦éœ€è¦RAGæ£€ç´¢: {need_rag}")

        # ç¬¬äºŒæ­¥ï¼šæ ¹æ®æ„å›¾å†³å®šæ˜¯å¦è¿›è¡ŒGraphRAGæ£€ç´¢
        graph_context = ""
        graph_entities = []
        keywords = []
        academic_info_matches = []
        academic_case_matches = []
        academic_info_context = ""
        academic_case_context = ""

        if need_rag:
            # ä½¿ç”¨çŸ¥è¯†å›¾è°±æ£€ç´¢ç›¸å…³çŸ¥è¯†
            logger.info(f"[å›¾è°±æ£€ç´¢] é—®é¢˜: {question}")

            retrieval_result = graph_retriever.retrieve_for_question(question, top_k=top_k, history=history)

            if retrieval_result.get('success'):
                graph_context = retrieval_result.get('context', '')
                graph_entities = retrieval_result.get('entities', [])
                keywords = retrieval_result.get('keywords', [])
                entity_count = retrieval_result.get('entity_count', 0)

                if entity_count > 0:
                    logger.info(f"[å›¾è°±æ£€ç´¢æˆåŠŸ] æ£€ç´¢åˆ° {entity_count} ä¸ªç›¸å…³å®ä½“")
                else:
                    logger.info("[å›¾è°±æ£€ç´¢] æœªæ‰¾åˆ°ç›¸å…³å®ä½“")

                if keywords:
                    logger.info(f"[å…³é”®å­—] ä»é—®é¢˜ä¸­æå–çš„å…³é”®è¯: {keywords}")

                    # è°ƒç”¨æ•™åŠ¡ä¿¡æ¯æœåŠ¡è¿›è¡Œå…³é”®è¯æ£€ç´¢
                    info_search = academic_info_service.search_by_keywords(keywords, limit=3)
                    if info_search.get('success'):
                        academic_info_matches = info_search.get('data', [])
                        if academic_info_matches:
                            academic_info_context = build_academic_info_context(academic_info_matches)
                            logger.info(f"[å…³é”®è¯æ£€ç´¢] åŒ¹é…åˆ° {len(academic_info_matches)} æ¡æ•™åŠ¡ä¿¡æ¯")
                    else:
                        logger.error(f"[å…³é”®è¯æ£€ç´¢] æ•™åŠ¡ä¿¡æ¯æ£€ç´¢å¤±è´¥: {info_search.get('error')}")
                        academic_info_matches = []
                        academic_info_context = ""

                    # è°ƒç”¨æ•™åŠ¡æ¡ˆä¾‹æœåŠ¡è¿›è¡Œå…³é”®è¯æ£€ç´¢
                    case_search = academic_case_service.search_by_keywords(keywords, limit=3)
                    if case_search.get('success'):
                        academic_case_matches = case_search.get('data', [])
                        if academic_case_matches:
                            academic_case_context = build_academic_case_context(academic_case_matches)
                            logger.info(f"[å…³é”®è¯æ£€ç´¢] åŒ¹é…åˆ° {len(academic_case_matches)} æ¡æ•™åŠ¡æ¡ˆä¾‹ä¿¡æ¯")
                    else:
                        logger.error(f"[å…³é”®è¯æ£€ç´¢] æ•™åŠ¡æ¡ˆä¾‹æ£€ç´¢å¤±è´¥: {case_search.get('error')}")
                        academic_case_matches = []
                        academic_case_context = ""
            else:
                logger.error(f"[å›¾è°±æ£€ç´¢å¤±è´¥] {retrieval_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                # å›¾è°±æ£€ç´¢å¤±è´¥ä¸å½±å“ä¸»æµç¨‹ï¼Œç»§ç»­æ‰§è¡Œ
        else:
            # ä¸éœ€è¦RAGæ£€ç´¢ï¼Œç›´æ¥å›ç­”
            logger.info("[æ„å›¾è¯†åˆ«] åˆ¤å®šä¸ºæ—¥å¸¸å¯¹è¯ï¼Œä¸è¿›è¡ŒGraphRAGæ£€ç´¢")

        # ç¬¬ä¸‰æ­¥ï¼šæ„å»ºæç¤ºè¯
        # æ„å»ºå¯¹è¯å†å²ä¸Šä¸‹æ–‡
        history_context = ""
        if history:
            history_parts = []
            for msg in history[-6:]:  # åªä¿ç•™æœ€è¿‘3è½®å¯¹è¯ï¼ˆ6æ¡æ¶ˆæ¯ï¼‰
                role = msg.get('role', '')
                content = msg.get('content', '')
                if role == 'user':
                    history_parts.append(f"ç”¨æˆ·: {content}")
                elif role == 'assistant':
                    history_parts.append(f"åŠ©æ‰‹: {content}")

            if history_parts:
                history_context = "\n\nã€å¯¹è¯å†å²ã€‘\n" + "\n".join(history_parts) + "\n"

        # æ ¹æ®æ˜¯å¦éœ€è¦GraphRAGæ£€ç´¢ï¼Œæ„å»ºä¸åŒçš„æç¤ºè¯
        context_parts = []
        if image_analysis_result:
            context_parts.append(f"ã€å›¾ç‰‡åˆ†æã€‘\n{image_analysis_result}")
        if graph_context:
            context_parts.append("ã€çŸ¥è¯†å›¾è°±ä¿¡æ¯ã€‘\n" + graph_context)
        if academic_info_context:
            context_parts.append(academic_info_context)
        if academic_case_context:
            context_parts.append(academic_case_context)

        combined_context = "\n\n".join(context_parts)

        if combined_context:
            source_labels = []
            if graph_context:
                source_labels.append("çŸ¥è¯†å›¾è°±ä¿¡æ¯")
            if academic_info_context:
                source_labels.append("æ•™åŠ¡åŸºç¡€ä¿¡æ¯")
            if academic_case_context:
                source_labels.append("æ•™åŠ¡æ¡ˆä¾‹ä¿¡æ¯")
            if image_analysis_result:
                source_labels.append("å›¾ç‰‡åˆ†æç»“æœ")

            sources_note = "ã€".join(source_labels) if source_labels else "è¡¥å……èµ„æ–™"

            system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™åŠ¡å’¨è¯¢çŸ¥è¯†åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹{sources_note}å’Œå¯¹è¯å†å²ï¼Œå‡†ç¡®å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
{history_context}
æ£€ç´¢åˆ°çš„ç›¸å…³å†…å®¹ï¼š
{combined_context}

å›ç­”è¦æ±‚ï¼š
1. å¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠä»£è¯ï¼ˆå¦‚"å®ƒ"ã€"è¿™ä¸ª"ã€"é‚£ä¸ª"ç­‰ï¼‰ï¼Œè¯·ç»“åˆå¯¹è¯å†å²ç†è§£æŒ‡ä»£å†…å®¹
2. å……åˆ†åˆ©ç”¨æä¾›çš„ç»“æ„åŒ–ä¿¡æ¯ï¼ˆçŸ¥è¯†å›¾è°±ã€æ”¿ç­–æ–‡ä»¶ã€è¯¾ç¨‹ä¿¡æ¯ç­‰ï¼‰ï¼Œä¸è¦é—æ¼å…³é”®äº‹å®
3. å›ç­”å¿…é¡»ä¸¥æ ¼åŸºäºæä¾›çš„èµ„æ–™ï¼Œä¸å¾—ç¼–é€ ä¿¡æ¯ï¼›è‹¥èµ„æ–™ä¸è¶³ï¼Œè¯·æ˜ç¡®è¯´æ˜
4. å¦‚æœ‰å›¾ç‰‡åˆ†æç»“æœï¼Œè¯·ç»“åˆå›¾ç‰‡ä¸­çš„ä¿¡æ¯è¿›è¡Œåˆ†æ
5. å¼•ç”¨å†…å®¹æ—¶ï¼Œè¯·æ³¨æ˜æ¥æºï¼ˆä¾‹å¦‚å…³è”çš„æ”¿ç­–åç§°ã€è¯¾ç¨‹ä»£ç æˆ–çŸ¥è¯†å›¾è°±å®ä½“ï¼‰
6. å›ç­”è¦å‡†ç¡®ã€ä¸“ä¸šã€ç®€æ´ï¼Œä¼˜å…ˆä½¿ç”¨æ•™åŠ¡è¡Œä¸šæœ¯è¯­å’Œæ ‡å‡†
7. å¦‚æœæ¶‰åŠæ”¿ç­–åç§°ã€æ—¶é—´ã€æµç¨‹æ­¥éª¤ç­‰ç»“æ„åŒ–ä¿¡æ¯ï¼Œè¯·æ¸…æ™°åœ°ç»„ç»‡ç­”æ¡ˆ"""
        else:
            # æ— æ£€ç´¢ç»“æœï¼ˆæ—¥å¸¸å¯¹è¯æˆ–ä»…å›¾ç‰‡åˆ†æï¼‰ï¼Œæ„å»ºé€šç”¨æç¤ºè¯
            if image_analysis_result:
                # æœ‰å›¾ç‰‡ä½†æ— GraphRAGæ£€ç´¢
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•™åŠ¡å’¨è¯¢æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºä»¥ä¸‹å›¾ç‰‡åˆ†æç»“æœå’Œå¯¹è¯å†å²ï¼Œå›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
{history_context}
ã€å›¾ç‰‡åˆ†æã€‘
{image_analysis_result}

å›ç­”è¦æ±‚ï¼š
1. å……åˆ†ç»“åˆå›¾ç‰‡åˆ†æç»“æœç»™å‡ºä¸“ä¸šçš„æ•™åŠ¡ç›¸å…³è§£ç­”å’Œå»ºè®®
2. å¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠä»£è¯ï¼Œè¯·ç»“åˆå¯¹è¯å†å²ç†è§£æŒ‡ä»£å†…å®¹
3. ä¿æŒä¸“ä¸šã€å‡†ç¡®çš„è¯­æ°”
4. å¦‚æœéœ€è¦æ›´è¯¦ç»†çš„ä¿¡æ¯ï¼Œå¯ä»¥å»ºè®®ç”¨æˆ·æä¾›æ›´å¤šç»†èŠ‚æˆ–æŸ¥è¯¢çŸ¥è¯†å›¾è°±"""
            else:
                # æ—¥å¸¸å¯¹è¯
                system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„æ•™åŠ¡å’¨è¯¢æ™ºèƒ½åŠ©æ‰‹ã€‚è¯·åŸºäºå¯¹è¯å†å²ï¼Œè‡ªç„¶åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚
{history_context}
å›ç­”è¦æ±‚ï¼š
1. å¦‚æœæ˜¯æ‰“æ‹›å‘¼ã€æ„Ÿè°¢ç­‰æ—¥å¸¸å¯¹è¯ï¼Œè¯·å‹å¥½ã€ç®€æ´åœ°å›åº”
2. å¦‚æœç”¨æˆ·è¯¢é—®ä½ çš„èƒ½åŠ›ï¼Œè¯·å‘ŠçŸ¥ä½ å¯ä»¥å¸®åŠ©å›ç­”æ•™åŠ¡æ”¿ç­–ã€è¯¾ç¨‹ä¿¡æ¯ã€é€‰è¯¾æŒ‡å¯¼ã€å­¦åˆ†è®¤å®šç­‰ç›¸å…³çš„ä¸“ä¸šé—®é¢˜ï¼Œä¹Ÿæ”¯æŒé€šè¿‡çŸ¥è¯†å›¾è°±æ£€ç´¢å’Œå›¾ç‰‡åˆ†æ
3. å¦‚æœç”¨æˆ·é—®é¢˜æ¶‰åŠä»£è¯ï¼Œè¯·ç»“åˆå¯¹è¯å†å²ç†è§£æŒ‡ä»£å†…å®¹
4. ä¿æŒä¸“ä¸šã€å‹å¥½çš„è¯­æ°”"""

        # ç¬¬ä¸‰æ­¥ï¼šè°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ
        logger.info("[LLM] è°ƒç”¨LLMç”Ÿæˆç­”æ¡ˆ...")
        llm = TextAnalysis()
        llm_result = llm.send_message(question, system_prompt)

        if not llm_result.get('success'):
            logger.error(f"[LLMå¤±è´¥] ç”Ÿæˆç­”æ¡ˆå¤±è´¥: {llm_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
            return error(f"LLMç”Ÿæˆç­”æ¡ˆå¤±è´¥: {llm_result.get('error', 'æœªçŸ¥é”™è¯¯')}")

        answer = llm_result.get('result', '')
        logger.info("[LLMæˆåŠŸ] ç­”æ¡ˆç”ŸæˆæˆåŠŸ")

        # ç¬¬å››æ­¥ï¼šè½¬å­˜æ£€ç´¢åˆ°çš„æ•™åŠ¡å’Œæ¡ˆä¾‹å›¾ç‰‡ï¼ˆé˜²æ­¢åŸå›¾è¢«åˆ é™¤ï¼‰
        if academic_info_matches or academic_case_matches:
            logger.info(f"[å›¾ç‰‡è½¬å­˜] å¼€å§‹è½¬å­˜æ•™åŠ¡å’Œæ¡ˆä¾‹å›¾ç‰‡åˆ°{QA_IMAGES_BUCKET}å­˜å‚¨æ¡¶")
            try:
                academic_info_matches, academic_case_matches = _copy_images_to_qa_storage(
                    academic_info_matches,
                    academic_case_matches
                )
                logger.info("[å›¾ç‰‡è½¬å­˜] å›¾ç‰‡è½¬å­˜å®Œæˆ")
            except Exception as e:
                logger.error(f"[é”™è¯¯] å›¾ç‰‡è½¬å­˜è¿‡ç¨‹å‡ºé”™: {str(e)}")
                # æ³¨æ„ï¼šè½¬å­˜å¤±è´¥æ—¶ï¼Œå¤±è´¥çš„å›¾ç‰‡æ•°æ®å·²åœ¨å‡½æ•°å†…éƒ¨è¢«æ¸…ç©º

        # ç¬¬äº”æ­¥ï¼šä¿å­˜é—®ç­”å†å²åˆ°æ•°æ®åº“
        try:
            # è°ƒè¯•ï¼šè¾“å‡ºè½¬å­˜åçš„æ•°æ®ç»“æ„
            if academic_info_matches:
                logger.debug(f"[è°ƒè¯•] ä¿å­˜å‰çš„academic_info_matches:")
                for idx, info in enumerate(academic_info_matches):
                    logger.debug(f"  [{idx}] bucket={info.get('image_bucket')}, object_key={info.get('image_object_key')}")

            if academic_case_matches:
                logger.debug(f"[è°ƒè¯•] ä¿å­˜å‰çš„academic_case_matches:")
                for idx, case in enumerate(academic_case_matches):
                    if case.get('images'):
                        logger.debug(f"  [{idx}] {case.get('case_title')} - {len(case['images'])} å¼ å›¾ç‰‡:")
                        for img_idx, img in enumerate(case['images']):
                            logger.debug(f"    [{img_idx}] bucket={img.get('bucket')}, object_key={img.get('object_key')}")

            # å°†çŸ¥è¯†å›¾è°±å®ä½“åˆ—è¡¨è½¬ä¸ºJSONå­—ç¬¦ä¸²å­˜å‚¨
            related_entities_json = json.dumps([
                {
                    'name': entity.get('name', ''),
                    'type': entity.get('type', ''),
                    'properties': entity.get('properties', {})
                }
                for entity in graph_entities
            ], ensure_ascii=False)

            academic_info_json = json.dumps(academic_info_matches, ensure_ascii=False)
            academic_case_json = json.dumps(academic_case_matches, ensure_ascii=False)
            keywords_json = json.dumps(keywords, ensure_ascii=False)

            sql = """
            INSERT INTO qa_history (conversation_id, question, answer, related_entities, graph_context,
                                   disease_info_matches, disease_case_matches, keywords,
                                   image_bucket, image_object_key, image_url, user_id, user_name)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            """
            db.execute(sql, (
                conversation_id,
                question,
                answer,
                related_entities_json,
                graph_context,
                academic_info_json,
                academic_case_json,
                keywords_json,
                image_bucket,
                image_object_key,
                image_url,
                user_id,
                user_name
            ))
            logger.info(f"[ä¿å­˜æˆåŠŸ] é—®ç­”å†å²å·²ä¿å­˜åˆ°ä¼šè¯{conversation_id}")

            # æ›´æ–°ä¼šè¯çš„update_time
            update_conv_sql = "UPDATE conversation SET update_time = CURRENT_TIMESTAMP WHERE id = ?"
            db.execute(update_conv_sql, (conversation_id,))
        except Exception as e:
            logger.error(f"[é”™è¯¯] ä¿å­˜é—®ç­”å†å²å¤±è´¥: {str(e)}")
            import traceback
            traceback.print_exc()
            return error(f'ä¿å­˜é—®ç­”å†å²å¤±è´¥: {str(e)}')

        # ç¬¬å…­æ­¥ï¼šè¿”å›ç»“æœ
        result = {
            'question': question,
            'answer': answer,
            'related_entities': graph_entities,  # è¿”å›ç›¸å…³çš„çŸ¥è¯†å›¾è°±å®ä½“
            'graph_context': graph_context,
            'image_url': image_url if image_url else None,  # è¿”å›å›¾ç‰‡URLï¼ˆå¦‚æœæœ‰ï¼‰
            'academic_info_matches': academic_info_matches,
            'academic_case_matches': academic_case_matches,
            'academic_info_context': academic_info_context,
            'academic_case_context': academic_case_context,
            'keywords': keywords
        }

        # è®¡ç®—å¹¶è®°å½•å“åº”æ—¶é—´
        end_time = time.time()
        response_time = round(end_time - start_time, 2)
        logger.info(f"[å“åº”] ç”¨æˆ· {user_id} èŠå¤©è¯·æ±‚å¤„ç†å®Œæˆï¼Œå“åº”æ—¶é—´ï¼š{response_time}ç§’ï¼Œæ¥å£ï¼š/qa/chat")
        logger.debug(f"[å“åº”è¯¦æƒ…] é—®é¢˜: {question[:100]}...ï¼Œå›ç­”é•¿åº¦: {len(answer)}å­—ç¬¦ï¼Œç›¸å…³å®ä½“æ•°: {len(graph_entities)}")

        return success(result, 'å›ç­”æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] æ™ºèƒ½é—®ç­”å¤±è´¥: {str(e)}")
        # å®‰å…¨åœ°è®¿é—®å˜é‡ï¼Œé¿å…UnboundLocalError
        question_str = f"{question[:100]}..." if 'question' in locals() and question else 'æœªè·å–'
        conversation_id_str = str(conversation_id) if 'conversation_id' in locals() and conversation_id is not None else 'æœªè·å–'
        logger.error(f"[é”™è¯¯è¯¦æƒ…] ç”¨æˆ·ID: {user_id}ï¼Œé—®é¢˜: {question_str}ï¼Œä¼šè¯ID: {conversation_id_str}")
        import traceback
        traceback.print_exc()
        return error(f'æ™ºèƒ½é—®ç­”å¤±è´¥: {str(e)}')


@qa_bp.route('/history', methods=['GET'])
@token_required
def get_qa_history():
    """
    è·å–é—®ç­”å†å²åˆ—è¡¨

    Query Parameters:
        page: é¡µç ï¼Œé»˜è®¤1
        page_size: æ¯é¡µæ¡æ•°ï¼Œé»˜è®¤10

    Response:
        {
            "code": 200,
            "message": "è·å–æˆåŠŸ",
            "data": {
                "list": [...],
                "total": 100,
                "page": 1,
                "page_size": 10
            }
        }
    """
    try:
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
        user = get_current_user()
        user_id = user.id

        # è·å–åˆ†é¡µå‚æ•°
        page = request.args.get('page', 1, type=int)
        page_size = request.args.get('page_size', 10, type=int)

        # å‚æ•°æ ¡éªŒ
        if page < 1:
            page = 1
        if page_size < 1 or page_size > 100:
            page_size = 10

        # è®¡ç®—åç§»é‡
        offset = (page - 1) * page_size

        # æ„å»ºæŸ¥è¯¢æ¡ä»¶
        # ç®¡ç†å‘˜å¯ä»¥æŸ¥çœ‹æ‰€æœ‰å†å²ï¼Œæ™®é€šç”¨æˆ·åªèƒ½æŸ¥çœ‹è‡ªå·±çš„
        if is_admin():  # ç®¡ç†å‘˜
            count_sql = "SELECT COUNT(*) as total FROM qa_history"
            list_sql = """
            SELECT id, question, answer, related_entities, graph_context,
                   disease_info_matches, disease_case_matches, keywords,
                   image_url, user_id, user_name, create_time
            FROM qa_history
            ORDER BY create_time DESC
            LIMIT ? OFFSET ?
            """
            count_result = db.query(count_sql, fetchone=True)
            history_list = db.query(list_sql, (page_size, offset))
        else:  # æ™®é€šç”¨æˆ·
            count_sql = "SELECT COUNT(*) as total FROM qa_history WHERE user_id = ?"
            list_sql = """
            SELECT id, question, answer, related_entities, graph_context,
                   disease_info_matches, disease_case_matches, keywords,
                   image_url, user_id, user_name, create_time
            FROM qa_history
            WHERE user_id = ?
            ORDER BY create_time DESC
            LIMIT ? OFFSET ?
            """
            count_result = db.query(count_sql, (user_id,), fetchone=True)
            history_list = db.query(list_sql, (user_id, page_size, offset))

        # è·å–æ€»æ•°
        total = count_result.get('total', 0) if count_result else 0

        # è§£æ JSON å­—æ®µ
        for item in history_list:
            try:
                related_entities_str = item.get('related_entities', '[]')
                item['related_entities'] = json.loads(related_entities_str) if related_entities_str else []
            except:
                item['related_entities'] = []

            try:
                info_str = item.get('disease_info_matches', '[]')
                item['disease_info_matches'] = json.loads(info_str) if info_str else []
            except:
                item['disease_info_matches'] = []

            try:
                case_str = item.get('disease_case_matches', '[]')
                item['disease_case_matches'] = json.loads(case_str) if case_str else []
            except:
                item['disease_case_matches'] = []

            try:
                keywords_str = item.get('keywords', '[]')
                parsed_keywords = json.loads(keywords_str) if keywords_str else []
                item['keywords'] = parsed_keywords if isinstance(parsed_keywords, list) else []
            except:
                item['keywords'] = []

            # graph_context å·²ç»æ˜¯å­—ç¬¦ä¸²ï¼Œæ— éœ€è§£æ
            if not item.get('graph_context'):
                item['graph_context'] = ''
            if item['disease_info_matches']:
                item['academic_info_context'] = build_academic_info_context(item['disease_info_matches'])
            else:
                item['academic_info_context'] = ''

            if item['disease_case_matches']:
                item['academic_case_context'] = build_academic_case_context(item['disease_case_matches'])
            else:
                item['academic_case_context'] = ''

        # è¿”å›ç»“æœ
        result = {
            'list': history_list,
            'total': total,
            'page': page,
            'page_size': page_size
        }

        return success(result, 'è·å–é—®ç­”å†å²æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] è·å–é—®ç­”å†å²å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'è·å–é—®ç­”å†å²å¤±è´¥: {str(e)}')


@qa_bp.route('/history/<int:qa_id>', methods=['DELETE'])
@token_required
def delete_qa_history(qa_id):
    """
    åˆ é™¤é—®ç­”å†å²è®°å½•

    Args:
        qa_id: é—®ç­”å†å²ID

    Response:
        {
            "code": 200,
            "message": "åˆ é™¤æˆåŠŸ"
        }
    """
    try:
        # è·å–å½“å‰ç”¨æˆ·ä¿¡æ¯
        user = get_current_user()
        user_id = user.id

        # ç¬¬ä¸€æ­¥ï¼šæŸ¥è¯¢è®°å½•è¯¦æƒ…ï¼ˆç”¨äºæƒé™æ£€æŸ¥å’Œåˆ é™¤å›¾ç‰‡ï¼‰
        check_sql = """
        SELECT id, user_id, image_bucket, image_object_key, disease_info_matches, disease_case_matches
        FROM qa_history
        WHERE id = ?
        """
        qa_record = db.query(check_sql, (qa_id,), fetchone=True)

        if not qa_record:
            return error('é—®ç­”è®°å½•ä¸å­˜åœ¨')

        # æƒé™æ£€æŸ¥ï¼šç®¡ç†å‘˜å¯ä»¥åˆ é™¤ä»»ä½•è®°å½•ï¼Œæ™®é€šç”¨æˆ·åªèƒ½åˆ é™¤è‡ªå·±çš„
        if not is_admin() and qa_record.get('user_id') != user_id:
            return error('æ— æƒåˆ é™¤æ­¤è®°å½•')

        # ç¬¬äºŒæ­¥ï¼šåˆ é™¤è½¬å­˜çš„å›¾ç‰‡
        logger.info(f"[åˆ é™¤é—®ç­”è®°å½•] è®°å½•ID: {qa_id}ï¼Œå¼€å§‹åˆ é™¤è½¬å­˜å›¾ç‰‡")
        _delete_qa_images_from_records([qa_record])

        # ç¬¬ä¸‰æ­¥ï¼šåˆ é™¤æ•°æ®åº“è®°å½•
        delete_sql = "DELETE FROM qa_history WHERE id = ?"
        db.execute(delete_sql, (qa_id,))

        return success(None, 'åˆ é™¤é—®ç­”å†å²æˆåŠŸ')

    except Exception as e:
        logger.error(f"[é”™è¯¯] åˆ é™¤é—®ç­”å†å²å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()
        return error(f'åˆ é™¤é—®ç­”å†å²å¤±è´¥: {str(e)}')
